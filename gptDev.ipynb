{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKGy2gWUpbbS2NomsmFB+Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vWdbfaG58fgV"},"outputs":[],"source":["# Adding all of the imports\n","from google.colab import drive\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from collections import Counter\n","from typing import Tuple\n"]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","file_path = '/content/drive/My Drive/DataAnalysisFiles/CreatingMyOwnGPT/input.txt'\n","\n","with open(file_path, 'r') as file:\n","  text = file.read()\n"],"metadata":{"id":"HWbBe4Hi-Z6t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735249009528,"user_tz":360,"elapsed":669,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"e9b3e003-29dd-47aa-c32e-33175114356b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["number = len(text)\n","formatted_number = \"{:,}\".format(number)\n","print(\"Length of dataset in characters: \", formatted_number)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fb-yj4DuCyA8","executionInfo":{"status":"ok","timestamp":1735249009528,"user_tz":360,"elapsed":5,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"8c4a4b36-8ed6-4141-e861-0bdbdcaa2460"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of dataset in characters:  1,115,393\n"]}]},{"cell_type":"code","source":["print(text[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWNqAXiUEKxV","executionInfo":{"status":"ok","timestamp":1735249009528,"user_tz":360,"elapsed":4,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"f1ae91b9-0ed8-42b0-f4ed-bc4dfc8e0a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor citizens, the patricians good.\n","What authority surfeits on would relieve us: if they\n","would yield us but the superfluity, while it were\n","wholesome, we might guess they relieved us humanely;\n","but they think we are too dear: the leanness that\n","afflicts us, the object of our misery, is as an\n","inventory to particularise their abundance; our\n","sufferance is a gain to them Let us revenge this with\n","our pikes, ere we become rakes: for the gods know I\n","speak this in hunger for bread, not in thirst for revenge.\n","\n","\n"]}]},{"cell_type":"code","source":["# We get all of the unique characters that occur in this text\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(''.join(chars))\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i851_ROoElW4","executionInfo":{"status":"ok","timestamp":1735249009528,"user_tz":360,"elapsed":3,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"86a45bd3-3fbd-4e44-f01a-071d808d9256"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n"]}]},{"cell_type":"code","source":["# create a mapping from characters to integers\n","stoi = {ch:i for i, ch in enumerate(chars)}\n","itos = {i:ch for i, ch in enumerate(chars)}\n","\n","encode = lambda s: [stoi[c] for c in s]\n","decode = lambda l: ''.join([itos[i] for i in l])\n","\n","print(encode(\"the sun will rise again\"))\n","print(decode(encode(\"the sun will rise again\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4GAeW5g8FUfH","executionInfo":{"status":"ok","timestamp":1735249009660,"user_tz":360,"elapsed":134,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"6038ab61-2f7a-47a8-cda5-0b2c08bc177a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[58, 46, 43, 1, 57, 59, 52, 1, 61, 47, 50, 50, 1, 56, 47, 57, 43, 1, 39, 45, 39, 47, 52]\n","the sun will rise again\n"]}]},{"cell_type":"code","source":["# encoding the entire text dataset and store it into torch\n","data = torch.tensor(encode(text), dtype = torch.long)\n","print(data.shape, data.dtype)\n","print(data[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hd8XRp4cgD7i","executionInfo":{"status":"ok","timestamp":1735249009788,"user_tz":360,"elapsed":130,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"defacd19-1d8a-4228-ec73-38e29908557e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1115393]) torch.int64\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n","         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n","        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n","        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n","         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n","         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n","        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n","        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n","         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n","        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n","        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n","        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n","        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n","        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n","        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n","         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n","         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n","         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n","        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n","        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n","        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n","        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n","        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n","        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n","         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n","         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n","        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n","        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n","        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n","         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n","        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n","        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n","         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n","        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n","        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n","        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n","        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n","        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n","        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n","        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n","        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n","        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n","         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n","        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n","        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n","        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n","        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n","        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n","        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"]}]},{"cell_type":"code","source":["# Splitting the data into train and validation sets\n","n = int(0.9*len(data))\n","training_data = data[:n]\n","validation_data = data[n:]"],"metadata":{"id":"si6EnjbNhUbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["block_size = 8\n","training_data[:block_size+1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jWfXKrThnaG","executionInfo":{"status":"ok","timestamp":1735249009788,"user_tz":360,"elapsed":6,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"f87807de-dc2d-4c31-e93f-b3409a39ba9b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["x = training_data[:block_size]\n","y = training_data[1:block_size+1]\n","for t in range(block_size):\n","  context = x[:t+1]\n","  target = y[t-1]\n","  print(f\"when input is {context} the target: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZxc11CMiH9_","executionInfo":{"status":"ok","timestamp":1735249009788,"user_tz":360,"elapsed":4,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"ad670072-624d-4eb1-a2c7-036989dfc15b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["when input is tensor([18]) the target: 58\n","when input is tensor([18, 47]) the target: 47\n","when input is tensor([18, 47, 56]) the target: 56\n","when input is tensor([18, 47, 56, 57]) the target: 57\n","when input is tensor([18, 47, 56, 57, 58]) the target: 58\n","when input is tensor([18, 47, 56, 57, 58,  1]) the target: 1\n","when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 15\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 47\n"]}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","batch_size = 4 # how many independent sequences will we process in parallel\n","block_size = 8 # what is the maximum context length for predictions ?\n","\n","def get_batch(split:str):\n","  # Generate a small batch of data of inputs x and target y\n","  data = training_data if split == 'train' else validation_data\n","  ix = torch.randint(len(data) - block_size, (batch_size,))\n","  x = torch.stack([data[i:i+block_size] for i in ix])\n","  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","  return x,y\n","\n","xb, yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape)\n","print(xb)\n","print('targets:')\n","print(yb.shape)\n","print(yb)\n","\n","print('---------------------------')\n","\n","for b in range(batch_size): # batch dimension\n","  for t in range(block_size): # time dimension\n","    context = xb[b, :t+1]\n","    target = yb[b, t]\n","    print(f\"when input is {context.tolist()} the target: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZNA9aE5Lr71s","executionInfo":{"status":"ok","timestamp":1735249009788,"user_tz":360,"elapsed":3,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"318f35a9-7bd0-479a-d2d6-596f47e9f653"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs:\n","torch.Size([4, 8])\n","tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n","        [49, 43, 43, 54,  1, 47, 58,  1],\n","        [13, 52, 45, 43, 50, 53,  8,  0],\n","        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n","targets:\n","torch.Size([4, 8])\n","tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n","        [43, 43, 54,  1, 47, 58,  1, 58],\n","        [52, 45, 43, 50, 53,  8,  0, 26],\n","        [39,  1, 46, 53, 59, 57, 43,  0]])\n","---------------------------\n","when input is [53] the target: 59\n","when input is [53, 59] the target: 6\n","when input is [53, 59, 6] the target: 1\n","when input is [53, 59, 6, 1] the target: 58\n","when input is [53, 59, 6, 1, 58] the target: 56\n","when input is [53, 59, 6, 1, 58, 56] the target: 47\n","when input is [53, 59, 6, 1, 58, 56, 47] the target: 40\n","when input is [53, 59, 6, 1, 58, 56, 47, 40] the target: 59\n","when input is [49] the target: 43\n","when input is [49, 43] the target: 43\n","when input is [49, 43, 43] the target: 54\n","when input is [49, 43, 43, 54] the target: 1\n","when input is [49, 43, 43, 54, 1] the target: 47\n","when input is [49, 43, 43, 54, 1, 47] the target: 58\n","when input is [49, 43, 43, 54, 1, 47, 58] the target: 1\n","when input is [49, 43, 43, 54, 1, 47, 58, 1] the target: 58\n","when input is [13] the target: 52\n","when input is [13, 52] the target: 45\n","when input is [13, 52, 45] the target: 43\n","when input is [13, 52, 45, 43] the target: 50\n","when input is [13, 52, 45, 43, 50] the target: 53\n","when input is [13, 52, 45, 43, 50, 53] the target: 8\n","when input is [13, 52, 45, 43, 50, 53, 8] the target: 0\n","when input is [13, 52, 45, 43, 50, 53, 8, 0] the target: 26\n","when input is [1] the target: 39\n","when input is [1, 39] the target: 1\n","when input is [1, 39, 1] the target: 46\n","when input is [1, 39, 1, 46] the target: 53\n","when input is [1, 39, 1, 46, 53] the target: 59\n","when input is [1, 39, 1, 46, 53, 59] the target: 57\n","when input is [1, 39, 1, 46, 53, 59, 57] the target: 43\n","when input is [1, 39, 1, 46, 53, 59, 57, 43] the target: 0\n"]}]},{"cell_type":"code","source":["class BigramLanguageModel(nn.Module):\n","\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        logits = self.token_embedding_table(idx) # (B,T,C)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # get the predictions\n","            logits, loss = self(idx)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx\n","\n","m = BigramLanguageModel(vocab_size)\n","logits, loss = m(xb, yb)\n","print(logits.shape)\n","print(loss)\n","\n","print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5irD3OtS6jgg","executionInfo":{"status":"ok","timestamp":1735249133102,"user_tz":360,"elapsed":116,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"a604532f-b059-4e0b-c50a-a90f6c30875a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 65])\n","tensor(4.7525, grad_fn=<NllLossBackward0>)\n","\n","hbH\n","\n",":CLP.A!fq'3ggt!O!T?X!!SA?W&TrpvYybSE3w&S BXUhmiKYyTmWMPhhmnHKj!!btgnwNNULuEzRuYyiWEQxPX!$3C'MBj\n"]}]},{"cell_type":"code","source":["# Creating a pytorch optimizer\n","optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"],"metadata":{"id":"rekdXlE58L4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","for steps in range(10000):\n","  xb, yb = get_batch('train')\n","\n","  logits, loss = m(xb, yb)\n","  optimizer.zero_grad(set_to_none=True)\n","  loss.backward()\n","  optimizer.step()\n","print(loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Zy8l5EvN84No","executionInfo":{"status":"ok","timestamp":1735250100846,"user_tz":360,"elapsed":20993,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"749b0781-67ab-4334-b295-69e0396cd933"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.5317542552948\n"]}]},{"cell_type":"code","source":["print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDWjqelr9-Xz","executionInfo":{"status":"ok","timestamp":1735250160579,"user_tz":360,"elapsed":283,"user":{"displayName":"Sai Hruthik Reddy Varakantham","userId":"08705985322335923250"}},"outputId":"04237824-6b14-49d5-b5bb-e78cf3e36f2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ICALLEnd at aveindecets wd n ude ierahe, p eld takenuerofunade myothe, prsthoulll plr s ayoup ovithrachy m's p:\n","CYOFoore;\n","\n","D:\n","\n","L:\n","Hin u\n","\n","Pellllprrsemee aley wire ye tear.\n","I\n","\n","MNGAghan thorg hone myotesesuse, s y wine heco,\n","\n","ANoincorsong p e ot bondshe uthatinde'lf tale! s grl t andatos biny.\n","\n","pletemat s od, r thayan\n","RUSCay h balined t he me moo ript coceay,\n","st.\n","\n","THOf atordonoke my t ISThe\n","Auth fel pemin, athe rugr it mey ofong I br ieninteery,\n","\n","Toorf anow, wid?\n","S:\n","IN plll tofullat tas?'ld dsaidir\n"]}]}]}